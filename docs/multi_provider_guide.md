# Multi-Provider Configuration Guide

**Datum:** 2026-02-08  
**Providers:** OpenAI (ChatGPT), Anthropic (Direct API), AWS Bedrock

---

## üéØ Verf√ºgbare Provider

### OpenAI (ChatGPT)
- ‚úÖ `gpt-4o-mini` - Schnell & g√ºnstig
- ‚úÖ `gpt-4o` - Beste Qualit√§t

### Anthropic (Direct API)
- ‚úÖ `claude-3-5-sonnet-20241022` - Beste Qualit√§t
- ‚úÖ `claude-3-5-haiku-20241022` - Schnell & g√ºnstig

### AWS Bedrock
- ‚úÖ `claude-3-5-sonnet-20241022-v2:0` - Via Bedrock
- ‚úÖ `claude-3-5-haiku-20241022-v1:0` - Via Bedrock

---

## üîß Setup

### 1. API Keys konfigurieren

Bearbeite `.env`:

```bash
# OpenAI
OPENAI_API_KEY=sk-proj-...

# Anthropic (Direct API)
ANTHROPIC_API_KEY=sk-ant-...  # Von https://console.anthropic.com/

# AWS Bedrock
AWS_PROFILE=man-nasys-dev-Admin
# Oder:
# AWS_ACCESS_KEY_ID=...
# AWS_SECRET_ACCESS_KEY=...
AWS_REGION=eu-central-1
```

---

## üöÄ Verwendung

### Option 1: Alle Provider testen (Standard)

Standardm√§√üig testet Promptfoo **alle 6 Provider gleichzeitig**:

```bash
npm run eval
```

**Ergebnis:** Vergleich aller Modelle in einer Tabelle

---

### Option 2: Nur bestimmte Provider

Bearbeite `promptfooconfig.yaml` und kommentiere ungew√ºnschte Provider aus:

```yaml
providers:
  # Nur OpenAI
  - id: openai:chat:gpt-4o-mini
    label: "GPT-4o Mini"
    config:
      temperature: 0
      max_tokens: 2048
      apiKey: env:OPENAI_API_KEY

  # Anthropic auskommentiert
  # - id: anthropic:messages:claude-3-5-sonnet-20241022
  #   label: "Claude 3.5 Sonnet (API)"
  #   config:
  #     temperature: 0
  #     max_tokens: 2048
  #     apiKey: env:ANTHROPIC_API_KEY

  # Bedrock auskommentiert
  # - id: bedrock:anthropic.claude-3-5-sonnet-20241022-v2:0
  #   label: "Claude 3.5 Sonnet (Bedrock)"
  #   config:
  #     region: eu-central-1
  #     max_tokens: 2048
  #     temperature: 0
```

---

### Option 3: Provider per CLI w√§hlen

```bash
# Nur GPT-4o Mini
npx promptfoo eval -c promptfooconfig.yaml --filter-providers "GPT-4o Mini"

# Nur Claude (Bedrock)
npx promptfoo eval -c promptfooconfig.yaml --filter-providers "Bedrock"

# Mehrere Provider
npx promptfoo eval -c promptfooconfig.yaml --filter-providers "GPT-4o,Claude"
```

---

## üìä Provider-Vergleich

### Kosten (pro 1M Tokens)

| Provider | Input | Output | Gesamt |
|----------|-------|--------|--------|
| **GPT-4o Mini** | $0.15 | $0.60 | $0.75 |
| **GPT-4o** | $2.50 | $10.00 | $12.50 |
| **Claude 3.5 Haiku (API)** | $0.80 | $4.00 | $4.80 |
| **Claude 3.5 Sonnet (API)** | $3.00 | $15.00 | $18.00 |
| **Claude 3.5 Haiku (Bedrock)** | $0.80 | $4.00 | $4.80 |
| **Claude 3.5 Sonnet (Bedrock)** | $3.00 | $15.00 | $18.00 |

### Performance

| Provider | Geschwindigkeit | Qualit√§t | Empfehlung |
|----------|----------------|----------|------------|
| **GPT-4o Mini** | ‚ö°‚ö°‚ö° | ‚≠ê‚≠ê‚≠ê | Development |
| **GPT-4o** | ‚ö°‚ö° | ‚≠ê‚≠ê‚≠ê‚≠ê‚≠ê | Production |
| **Claude 3.5 Haiku** | ‚ö°‚ö°‚ö° | ‚≠ê‚≠ê‚≠ê‚≠ê | Development |
| **Claude 3.5 Sonnet** | ‚ö°‚ö° | ‚≠ê‚≠ê‚≠ê‚≠ê‚≠ê | Production |

---

## üîÄ Wechseln zwischen Providern

### Schneller Wechsel (ohne Config-√Ñnderung)

Erstelle npm-Scripts f√ºr jeden Provider:

```json
// package.json
{
  "scripts": {
    "eval:openai": "npx promptfoo eval --filter-providers 'GPT-4o'",
    "eval:anthropic": "npx promptfoo eval --filter-providers 'Claude.*API'",
    "eval:bedrock": "npx promptfoo eval --filter-providers 'Bedrock'",
    "eval:all": "npm run eval"
  }
}
```

**Verwendung:**
```bash
npm run eval:openai      # Nur OpenAI
npm run eval:anthropic   # Nur Anthropic Direct API
npm run eval:bedrock     # Nur Bedrock
npm run eval:all         # Alle Provider
```

---

## üêõ Troubleshooting

### "API key not found"

**Problem:** `ANTHROPIC_API_KEY` nicht gesetzt

**L√∂sung:**
```bash
# .env
ANTHROPIC_API_KEY=sk-ant-api03-...
```

### "AWS credentials not found"

**Problem:** AWS-Credentials fehlen

**L√∂sung:**
```bash
# Option 1: AWS Profile
AWS_PROFILE=your-profile-name

# Option 2: Direct credentials
AWS_ACCESS_KEY_ID=AKIA...
AWS_SECRET_ACCESS_KEY=...
```

### "Rate limit exceeded"

**Problem:** Zu viele Requests

**L√∂sung:**
```yaml
# promptfooconfig.yaml
evaluateOptions:
  maxConcurrency: 1  # Reduziere von 5 auf 1
  delay: 1000        # 1 Sekunde Pause zwischen Requests
```

---

## üí° Best Practices

### Development
- Nutze **GPT-4o Mini** oder **Claude 3.5 Haiku**
- Schnell und g√ºnstig f√ºr Tests

### Production
- Nutze **GPT-4o** oder **Claude 3.5 Sonnet**
- Beste Qualit√§t f√ºr echte Evaluationen

### A/B Testing
- Aktiviere **alle Provider**
- Vergleiche Ergebnisse direkt

### Cost Optimization
- Nutze **Bedrock** statt Direct API (gleiche Kosten, aber bessere Limits)
- Setze `maxConcurrency` niedrig

---

## üìù Beispiel: Provider wechseln

### Schritt 1: Aktuell nur OpenAI

```yaml
providers:
  - id: openai:chat:gpt-4o-mini
    label: "GPT-4o Mini"
    # ...
```

```bash
npm run eval
# ‚Üí Nutzt nur GPT-4o Mini
```

### Schritt 2: Zu Anthropic wechseln

```yaml
providers:
  # - id: openai:chat:gpt-4o-mini  # Auskommentiert
  #   label: "GPT-4o Mini"
  
  - id: anthropic:messages:claude-3-5-sonnet-20241022
    label: "Claude 3.5 Sonnet (API)"
    # ...
```

```bash
npm run eval
# ‚Üí Nutzt nur Claude 3.5 Sonnet
```

### Schritt 3: Beide vergleichen

```yaml
providers:
  - id: openai:chat:gpt-4o-mini
    label: "GPT-4o Mini"
    # ...
  
  - id: anthropic:messages:claude-3-5-sonnet-20241022
    label: "Claude 3.5 Sonnet (API)"
    # ...
```

```bash
npm run eval
# ‚Üí Vergleicht beide Modelle
```

---

## ‚úÖ Zusammenfassung

**Jetzt hast du:**
- ‚úÖ 6 verschiedene Provider konfiguriert
- ‚úÖ Flexibles Wechseln zwischen Providern
- ‚úÖ Alle API Keys in `.env`
- ‚úÖ Vergleich mehrerer Modelle m√∂glich

**N√§chste Schritte:**
1. Setze `ANTHROPIC_API_KEY` in `.env` (falls du Anthropic nutzen willst)
2. Teste mit `npm run eval`
3. Vergleiche Ergebnisse in Promptfoo UI: `npm run eval:view`

---

**Erstellt:** 2026-02-08  
**Provider:** 6 (OpenAI x2, Anthropic x2, Bedrock x2)
