# ğŸï¸ VEEDS LLMOps Stack

Ein hochmoderner Enterprise-LLMOps-Stack zur Absicherung, Ãœberwachung und kontinuierlichen Verbesserung von Bedrock-basierten LLM-Anwendungen.

---

## ğŸ› ï¸ NPM Script Referenz

Hier sind alle verfÃ¼gbaren Befehle und ihr Zweck im LLMOps-Lifecycle:

### **1. Setup & Infrastruktur**
| Befehl | Aktion | Warum? |
| :--- | :--- | :--- |
| `npm run setup` | FÃ¼hrt `./setup.sh` aus | Generiert sichere Secrets fÃ¼r Langfuse und DBs. |
| `npm run up` | `docker compose up -d` | Startet den kompletten Stack (Langfuse, DBs, Presidio). |
| `npm run down` | `docker compose down` | Stoppt alle Dienste und gibt Ressourcen frei. |
| `npm run status` | `docker compose ps` | Zeigt den Gesundheitszustand aller Container an. |
| `npm run health` | `./scripts/health-check.sh` | PrÃ¼ft, ob APIs (Langfuse, Clickhouse) wirklich antworten. |

### **2. Entwicklung & Kern-Funktion**
| Befehl | Aktion | Warum? |
| :--- | :--- | :--- |
| `npm run build` | `tsc` | Kompiliert TypeScript nach JavaScript (`dist/`). |
| `npm run dev` | `tsx watch src/index.ts` | Startet Entwicklung mit Auto-Reload. |
| `npm run demo` | `npx tsx scripts/demo-proofreader.ts` | **End-to-End Test**: FÃ¼hrt PII-Filter, Bedrock-Call und Cost-Tracking aus. |

### **3. Evaluation & QualitÃ¤t (Promptfoo)**
| Befehl | Aktion | Warum? |
| :--- | :--- | :--- |
| `npm run eval` | Generiert Tests & fÃ¼hrt Eval aus | PrÃ¼ft Modell-Korrektheit gegen das Golden Dataset. |
| `npm run eval:view` | `promptfoo view` | Startet das Web-Dashboard zum Ergebnisvergleich. |
| `npm run eval:assert` | Eval mit Schwellenwerten | Ideal fÃ¼r CI/CD: bricht bei schlechter QualitÃ¤t ab. |
| `npm run eval:push` | Sendet Scores an Langfuse | VerknÃ¼pft Evaluierungsergebnisse mit Langfuse-Experimenten. |

### **4. Sicherheit & Performance**
| Befehl | Aktion | Warum? |
| :--- | :--- | :--- |
| `npm run redteam` | Startet Promptfoo Red Teaming | Sucht nach PII-Leaks, Injections und Halluzinationen. |
| `npm run test:load` | FÃ¼hrt k6 Lasttest aus | Misst Latenz (p95) und StabilitÃ¤t unter Last. |
| `npm run test:verify` | `scripts/verify-security.ts` | **Sicherheitscheck**: Validiert PII-Redaction und Injection-Filter. |

### **5. Feedback-Loop & Daten**
| Befehl | Aktion | Warum? |
| :--- | :--- | :--- |
| `npm run dataset:export` | `scripts/export-production-traces.ts` | **Full Circle**: Extrahiert reale Traces als neue Testcases. |
| `npm run dataset:upload`| LÃ¤dt Dataset in Langfuse hoch | Macht lokale Testdaten in der Cloud/UI verfÃ¼gbar. |
| `npm run seed` | Initialisiert Langfuse-Org | Bereitet die DB fÃ¼r den ersten Login vor. |

---

## ğŸ”„ LLMOps Workflow & Datenfluss

### **Der VEEDS "Full Circle" Lifecycle**

```mermaid
graph TD
    A[Design: Prompt in Langfuse] --> B[Develop: src/proofreader.ts]
    B --> C[Guard: privacy/pii-filter.ts]
    C --> D[Execute: AWS Bedrock Call]
    D --> E[Observe: Langfuse Traces + Cost]
    E --> F[Analyze: Feedback & Scores]
    F --> G[Extract: dataset:export]
    G --> H[Eval: eval script]
    H --> A
```

### **Datenfluss-Architektur**

1.  **Input**: Ein YAML-Fahrzeugdatensatz kommt rein.
2.  **Privacy**: `pii-filter.ts` sendet den Text an **MS Presidio**. Namen/Telefonnummern werden ersetzt.
3.  **LLM**: Der anonymisierte Text geht an **AWS Bedrock**.
4.  **Monitoring**: `cost-calculator.ts` berechnet Dollar-Kosten basierend auf Token-Usage.
5.  **Observability**: Der Log (Pino) und der Trace (Langfuse) werden mit der gleichen **Trace-ID** gespeichert.
6.  **Refinement**: Fehlerhafte Produktions-Traces werden per `dataset:export` in das `golden_dataset.json` Ã¼berfÃ¼hrt, um die Testabdeckung permanent zu erhÃ¶hen.

---

## ğŸ“Š Automatisch generierte Dateien

Die folgende Tabelle zeigt, welche Dateien vom System erzeugt werden und warum:

| Pfad | Erzeugt durch | Zweck |
| :--- | :--- | :--- |
| `/dist/` | `npm run build` | Kompilierter Produktionscode. |
| `eval/results/*.json` | `npm run eval` | Rohe Testergebnisse fÃ¼r Historie. |
| `eval/golden_dataset.json`| `npm run eval:generate` | KI-generierte Test-Datenbasis. |
| `promptfoo_data/` | Jede Evaluation | Lokale Cache-DB fÃ¼r schnellere/gÃ¼nstigere Tests. |
| `adversarial_tests.json` | `npm run redteam` | Generierte Angriffs-Vektoren. |
| `package-lock.json` | `npm install` | Fixierte Dependency-Versionen. |

---

## ğŸš€ Schnellstart-Workflow

Wenn du das System im Alltag nutzt, ist dies dein empfohlener Workflow:

1.  **Infrastruktur starten**: `npm run up`
2.  **Prompt anpassen**: In der Langfuse UI (http://localhost:3000)
3.  **Lokal testen**: `npm run demo` (PrÃ¼fe Kosten & PII Schutz)
4.  **QualitÃ¤t sichern**: `npm run eval` (PrÃ¼fe Regressionen)
5.  **Sicherheit prÃ¼fen**: `npm run test:verify` (Checke Injections)
6.  **Deploy**: Merge in `main` (CI/CD Automatisierung)

---
Â© 2026 VEEDS CORP - Advanced LLMOps Infrastructure
